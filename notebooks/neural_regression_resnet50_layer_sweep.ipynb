{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"/n/home12/binxuwang/Github/Closed-loop-visual-insilico\")\n",
    "import timm\n",
    "import torch\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "from tqdm.auto import tqdm\n",
    "from os.path import join\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from horama import maco, plot_maco\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms import ToPILImage, ToTensor, Normalize, Resize\n",
    "from torchvision.models import resnet50\n",
    "from circuit_toolkit.CNN_scorers import TorchScorer\n",
    "from circuit_toolkit.GAN_utils import upconvGAN, Caffenet\n",
    "from circuit_toolkit.plot_utils import to_imgrid, show_imgrid, save_imgrid, saveallforms\n",
    "from circuit_toolkit.layer_hook_utils import featureFetcher_module, featureFetcher, get_module_names\n",
    "from circuit_toolkit.dataset_utils import ImagePathDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from neural_regress.regress_lib import sweep_regressors\n",
    "from neural_regress.sklearn_torchify_lib import SRP_torch, PCA_torch, LinearRegression_torch, SpatialAvg_torch\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.random_projection import SparseRandomProjection, GaussianRandomProjection\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "#%% Utility Functions\n",
    "\n",
    "def load_neural_data(data_path, subject_id, stimroot):\n",
    "    \"\"\"Load neural data and image file paths.\"\"\"\n",
    "    from core.data_utils import load_from_hdf5\n",
    "    data = load_from_hdf5(data_path)\n",
    "    # Meta data\n",
    "    brain_area = data[subject_id][\"neuron_metadata\"][\"brain_area\"]\n",
    "    ncsnr = data[subject_id][\"neuron_metadata\"][\"ncsnr\"]\n",
    "    reliability = data[subject_id][\"neuron_metadata\"][\"reliability\"]\n",
    "    # Display parameters\n",
    "    stim_pos = data[subject_id]['trials']['stimulus_pos_deg']\n",
    "    stim_size = data[subject_id]['trials']['stimulus_size_pix']\n",
    "    # Response data\n",
    "    resp_mat = data[subject_id]['repavg']['response_peak']  # Peak, avg response\n",
    "    resp_temp_mat = data[subject_id]['repavg']['response_temporal']  # Temporal response\n",
    "    stimulus_names = data[subject_id]['repavg']['stimulus_name']\n",
    "    image_fps = [f\"{stimroot}/{stimname.decode('utf8')}\" for stimname in stimulus_names]\n",
    "    return {\n",
    "        'brain_area': brain_area,\n",
    "        'ncsnr': ncsnr,\n",
    "        'reliability': reliability,\n",
    "        'stim_pos': stim_pos,\n",
    "        'stim_size': stim_size,\n",
    "        'resp_mat': resp_mat,\n",
    "        'resp_temp_mat': resp_temp_mat,\n",
    "        'image_fps': image_fps,\n",
    "    }\n",
    "\n",
    "\n",
    "@th.no_grad()\n",
    "def record_features(model, fetcher, dataset, batch_size=20, device=\"cuda\"):\n",
    "    \"\"\"Record features from the model using the fetcher.\"\"\"\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    model.to(device).eval()\n",
    "    feat_col = {}\n",
    "    for imgs, _ in tqdm(loader):\n",
    "        model(imgs.to(device))\n",
    "        for key in fetcher.activations.keys():\n",
    "            if key not in feat_col:\n",
    "                feat_col[key] = []\n",
    "            feat_col[key].append(fetcher[key].cpu())\n",
    "    for key in feat_col.keys():\n",
    "        feat_col[key] = th.cat(feat_col[key], dim=0)\n",
    "        print(key, feat_col[key].shape)\n",
    "    return feat_col\n",
    "\n",
    "\n",
    "def extract_features(model, dataset, layer_name=\"last_block\", batch_size=20, device=\"cuda\"):\n",
    "    \"\"\"Extract features from a specified layer of the model.\"\"\"\n",
    "    fetcher = featureFetcher_module()\n",
    "    fetcher.record_module(model.layer4, layer_name, ) # this is for ResNet50, specifically, modify as needed\n",
    "    feat_dict = record_features(model, fetcher, dataset, batch_size=batch_size, device=device)\n",
    "    fetcher.cleanup()\n",
    "    del fetcher\n",
    "    return feat_dict\n",
    "\n",
    "\n",
    "def LinearLayer_from_sklearn(model):\n",
    "    \"\"\"Convert a sklearn linear model to a PyTorch Linear layer.\"\"\"\n",
    "    if isinstance(model, sklearn.model_selection._search.GridSearchCV):\n",
    "        model = model.best_estimator_\n",
    "    assert model.coef_.shape[1] == model.n_features_in_\n",
    "    readout = nn.Linear(model.coef_.shape[1], model.coef_.shape[0], bias=True)\n",
    "    readout.weight.data = th.tensor(model.coef_).float()\n",
    "    readout.bias.data = th.tensor(model.intercept_).float()\n",
    "    return readout\n",
    "\n",
    "\n",
    "def perform_regression(feat_dict, resp_mat, reliability, thresh=0.8, layerkey=\"last_block\",):\n",
    "    \"\"\"Perform regression using extracted features and neural responses.\"\"\"\n",
    "    # TODO: add customizable feature transforms\n",
    "    # TODO: add customizable regressors\n",
    "    # Preprocess features\n",
    "    feat_tsr = feat_dict[layerkey]\n",
    "    print(feat_tsr.shape)\n",
    "    featmat = feat_tsr.view(feat_tsr.shape[0], -1).numpy()\n",
    "    featmat_avg = feat_tsr.mean(dim=(2, 3))  # B x C\n",
    "    centpos = (feat_tsr.shape[2] // 2, feat_tsr.shape[3] // 2)\n",
    "    featmat_rf = feat_tsr[:, :, centpos[0]:centpos[0]+1, centpos[1]:centpos[1]+1].mean(dim=(2,3))  # B x n_components\n",
    "    # featmat_CLS = feat_tsr[:, 0, :].numpy()\n",
    "    Xdict = {\"sp_avg\": featmat_avg, \"sp_rf\": featmat_rf, 'none': featmat} # \"srp\": srp_featmat, \"pca\": pca_featmat,\n",
    "    # Xdict = {\"sp_avg\": featmat_avg, \"cls\": featmat_CLS}\n",
    "    # Define regressors\n",
    "    ridge = Ridge(alpha=1.0)\n",
    "    kr_rbf = KernelRidge(alpha=1.0, kernel=\"rbf\", gamma=None)\n",
    "    # Mask reliable channels\n",
    "    chan_mask = reliability > thresh\n",
    "    print(f\"Fitting models for reliable channels > {thresh} N={chan_mask.sum()}\")\n",
    "    regressors = [ridge, kr_rbf]\n",
    "    regressor_names = [\"Ridge\", \"KernelRBF\"]\n",
    "    result_df, fit_models = sweep_regressors(Xdict, resp_mat[:, chan_mask], regressors, regressor_names)\n",
    "    return result_df, fit_models, chan_mask, Xdict\n",
    "\n",
    "\n",
    "def perform_regression_sweeplayer(feat_dict, resp_mat, layer_names=None, \n",
    "                                  dimred_list=[\"pca1000\", \"sp_cent\", \"sp_avg\", \"full\",],\n",
    "                                  regressor_list=[\"Ridge\",], verbose=True,\n",
    "                                  pretrained_Xtransforms={}):\n",
    "    \"\"\"Perform regression using extracted features and neural responses.\"\"\"\n",
    "    # TODO: add customizable feature transforms\n",
    "    # TODO: add customizable regressors\n",
    "    # Preprocess features\n",
    "    Xdict = {}\n",
    "    tfm_dict = {}\n",
    "    for layerkey in feat_dict.keys() if layer_names is None else layer_names:\n",
    "        feat_tsr = feat_dict[layerkey]\n",
    "        print(layerkey, feat_tsr.shape)\n",
    "        featmat = feat_tsr.flatten(start_dim=1)\n",
    "        for dimred in dimred_list:\n",
    "            if dimred.startswith(\"pca\"):\n",
    "                n_components = int(dimred.split(\"pca\")[-1])\n",
    "                if f\"{layerkey}_{dimred}\" in pretrained_Xtransforms:\n",
    "                    pca_transformer = pretrained_Xtransforms[f\"{layerkey}_{dimred}\"]\n",
    "                    featmat_pca = pca_transformer.transform(featmat)\n",
    "                else:\n",
    "                    pca_transformer = PCA(n_components=n_components)\n",
    "                    featmat_pca = pca_transformer.fit_transform(featmat)\n",
    "                Xdict.update({f\"{layerkey}_{dimred}\": featmat_pca})\n",
    "                tfm_dict.update({f\"{layerkey}_{dimred}\": pca_transformer})\n",
    "            elif dimred == \"srp\":\n",
    "                srp_transformer = SparseRandomProjection()\n",
    "                featmat_srp = srp_transformer.fit_transform(featmat)\n",
    "                if f\"{layerkey}_{dimred}\" in pretrained_Xtransforms:\n",
    "                    srp_transformer = pretrained_Xtransforms[f\"{layerkey}_{dimred}\"]\n",
    "                    featmat_srp = srp_transformer.transform(featmat)\n",
    "                else:\n",
    "                    srp_transformer = SparseRandomProjection()\n",
    "                    featmat_srp = srp_transformer.fit_transform(featmat)\n",
    "                Xdict.update({f\"{layerkey}_{dimred}\": featmat_srp})\n",
    "                tfm_dict.update({f\"{layerkey}_{dimred}\": srp_transformer})\n",
    "            elif dimred.startswith(\"srp\"):\n",
    "                n_components = int(dimred.split(\"srp\")[-1])\n",
    "                if f\"{layerkey}_{dimred}\" in pretrained_Xtransforms:\n",
    "                    srp_transformer = pretrained_Xtransforms[f\"{layerkey}_{dimred}\"]\n",
    "                    featmat_srp = srp_transformer.transform(featmat)\n",
    "                else:\n",
    "                    srp_transformer = SparseRandomProjection(n_components=n_components)\n",
    "                    featmat_srp = srp_transformer.fit_transform(featmat)\n",
    "                Xdict.update({f\"{layerkey}_{dimred}\": featmat_srp})\n",
    "            elif dimred == \"sp_avg\":\n",
    "                featmat_avg = feat_tsr.mean(dim=(2, 3))  # B x C\n",
    "                Xdict.update({f\"{layerkey}_sp_avg\": featmat_avg})\n",
    "                tfm_dict.update({f\"{layerkey}_sp_avg\": lambda x: x.mean(dim=(2,3))})\n",
    "            elif dimred == \"sp_cent\":\n",
    "                centpos = (feat_tsr.shape[2] // 2, feat_tsr.shape[3] // 2)\n",
    "                featmat_cent = feat_tsr[:, :, centpos[0]:centpos[0]+1, centpos[1]:centpos[1]+1].mean(dim=(2,3))  # B x n_components\n",
    "                Xdict.update({f\"{layerkey}_sp_cent\": featmat_cent})\n",
    "                tfm_dict.update({f\"{layerkey}_sp_cent\": lambda x: x[:, :, centpos[0]:centpos[0]+1, centpos[1]:centpos[1]+1].mean(dim=(2,3))})\n",
    "            elif dimred == \"full\":\n",
    "                Xdict.update({f\"{layerkey}_full\": featmat})\n",
    "                tfm_dict.update({f\"{layerkey}_full\": lambda x: x.flatten(start_dim=1)})\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown dimension reduction method: {dimred}\")\n",
    "        \n",
    "    # Define regressors\n",
    "    regressors = []\n",
    "    for regressor_name in regressor_list:\n",
    "        if regressor_name == \"Ridge\":\n",
    "            regressors.append(Ridge(alpha=1.0))\n",
    "        elif regressor_name == \"KernelRBF\":\n",
    "            regressors.append(KernelRidge(alpha=1.0, kernel=\"rbf\", gamma=None))\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown regressor: {regressor_name}\")\n",
    "    regressor_names = regressor_list\n",
    "    \n",
    "    result_df, fit_models = sweep_regressors(Xdict, resp_mat, regressors, regressor_names, verbose=verbose)\n",
    "    return result_df, fit_models, Xdict, tfm_dict\n",
    "\n",
    "\n",
    "def perform_regression_sweeplayer_RidgeCV(feat_dict, resp_mat, layer_names=None, \n",
    "                                  dimred_list=[\"pca1000\", \"sp_cent\", \"sp_avg\", \"full\",],\n",
    "                                  alpha_list=[1E-4, 1E-3, 1E-2, 1E-1, 1, 10, 100, 1E3, 1E4, 1E5, 1E6, 1E7, 1E8, 1E9],\n",
    "                                  alpha_per_target=True,\n",
    "                                  pretrained_Xtransforms={},\n",
    "                                  verbose=True):\n",
    "    \"\"\"Perform regression using extracted features and neural responses.\"\"\"\n",
    "    # TODO: add customizable feature transforms\n",
    "    # TODO: add customizable regressors\n",
    "    # Preprocess features\n",
    "    Xdict = {}\n",
    "    tfm_dict = {}\n",
    "    for layerkey in feat_dict.keys() if layer_names is None else layer_names:\n",
    "        feat_tsr = feat_dict[layerkey]\n",
    "        print(layerkey, feat_tsr.shape)\n",
    "        featmat = feat_tsr.flatten(start_dim=1)\n",
    "        for dimred in dimred_list:\n",
    "            if dimred.startswith(\"pca\"):\n",
    "                n_components = int(dimred.split(\"pca\")[-1])\n",
    "                if f\"{layerkey}_{dimred}\" in pretrained_Xtransforms:\n",
    "                    pca_transformer = pretrained_Xtransforms[f\"{layerkey}_{dimred}\"]\n",
    "                    featmat_pca = pca_transformer.transform(featmat)\n",
    "                else:\n",
    "                    pca_transformer = PCA(n_components=n_components)\n",
    "                    featmat_pca = pca_transformer.fit_transform(featmat)\n",
    "                Xdict.update({f\"{layerkey}_{dimred}\": featmat_pca})\n",
    "                tfm_dict.update({f\"{layerkey}_{dimred}\": pca_transformer})\n",
    "            elif dimred == \"srp\":\n",
    "                srp_transformer = SparseRandomProjection()\n",
    "                featmat_srp = srp_transformer.fit_transform(featmat)\n",
    "                if f\"{layerkey}_{dimred}\" in pretrained_Xtransforms:\n",
    "                    srp_transformer = pretrained_Xtransforms[f\"{layerkey}_{dimred}\"]\n",
    "                    featmat_srp = srp_transformer.transform(featmat)\n",
    "                else:\n",
    "                    srp_transformer = SparseRandomProjection()\n",
    "                    featmat_srp = srp_transformer.fit_transform(featmat)\n",
    "                Xdict.update({f\"{layerkey}_{dimred}\": featmat_srp})\n",
    "                tfm_dict.update({f\"{layerkey}_{dimred}\": srp_transformer})\n",
    "            elif dimred.startswith(\"srp\"):\n",
    "                n_components = int(dimred.split(\"srp\")[-1])\n",
    "                if f\"{layerkey}_{dimred}\" in pretrained_Xtransforms:\n",
    "                    srp_transformer = pretrained_Xtransforms[f\"{layerkey}_{dimred}\"]\n",
    "                    featmat_srp = srp_transformer.transform(featmat)\n",
    "                else:\n",
    "                    srp_transformer = SparseRandomProjection(n_components=n_components)\n",
    "                    featmat_srp = srp_transformer.fit_transform(featmat)\n",
    "                Xdict.update({f\"{layerkey}_{dimred}\": featmat_srp})\n",
    "                tfm_dict.update({f\"{layerkey}_{dimred}\": srp_transformer})\n",
    "            elif dimred == \"sp_avg\":\n",
    "                featmat_avg = feat_tsr.mean(dim=(2, 3))  # B x C\n",
    "                Xdict.update({f\"{layerkey}_sp_avg\": featmat_avg})\n",
    "                tfm_dict.update({f\"{layerkey}_sp_avg\": lambda x: x.mean(dim=(2,3))})\n",
    "            elif dimred == \"sp_cent\":\n",
    "                centpos = (feat_tsr.shape[2] // 2, feat_tsr.shape[3] // 2)\n",
    "                featmat_cent = feat_tsr[:, :, centpos[0]:centpos[0]+1, centpos[1]:centpos[1]+1].mean(dim=(2,3))  # B x n_components\n",
    "                Xdict.update({f\"{layerkey}_sp_cent\": featmat_cent})\n",
    "                tfm_dict.update({f\"{layerkey}_sp_cent\": lambda x: x[:, :, centpos[0]:centpos[0]+1, centpos[1]:centpos[1]+1].mean(dim=(2,3))})\n",
    "            elif dimred == \"full\":\n",
    "                Xdict.update({f\"{layerkey}_full\": featmat})\n",
    "                tfm_dict.update({f\"{layerkey}_full\": lambda x: x.flatten(start_dim=1)})\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown dimension reduction method: {dimred}\")\n",
    "        \n",
    "    # Define regressors\n",
    "    regressors = [RidgeCV(alphas=alpha_list, alpha_per_target=alpha_per_target)]\n",
    "    regressor_names = [\"RidgeCV\"]\n",
    "    \n",
    "    result_df, fit_models = sweep_regressors(Xdict, resp_mat, regressors, regressor_names, verbose=verbose)\n",
    "    return result_df, fit_models, Xdict, tfm_dict\n",
    "\n",
    "\n",
    "def check_gradient(objective_fn):\n",
    "    \"\"\"Check if gradients can flow through the objective function.\"\"\"\n",
    "    img_opt = th.randn(1, 3, 224, 224).cuda()\n",
    "    img_opt.requires_grad_(True)\n",
    "    resp = objective_fn(img_opt)\n",
    "    resp.mean().backward()\n",
    "    print(resp.shape)\n",
    "    assert img_opt.grad is not None\n",
    "    \n",
    "\n",
    "def visualize_results(img_col, D2, ):\n",
    "    \"\"\"Visualize the optimized images.\"\"\"\n",
    "    row_num = len(img_col) // 5 + (len(img_col) % 5 > 0)\n",
    "    figh, axs = plt.subplots(row_num, 5, figsize=(25, row_num * 5))\n",
    "    for i, ax in enumerate(axs.flat):\n",
    "        plt.sca(ax)\n",
    "        if i >= len(img_col):\n",
    "            ax.axis(\"off\")\n",
    "            continue\n",
    "        tup = img_col[i]\n",
    "        plot_maco(tup[0], tup[1])\n",
    "        plt.title(f\"Unit {i} R2={D2[i]:.2f}\")\n",
    "\n",
    "\n",
    "def load_model_transform(modelname, device=\"cuda\"):\n",
    "    # Prepare model and transforms\n",
    "    if modelname == \"resnet50_robust\":\n",
    "        model = resnet50(pretrained=False)\n",
    "        model.load_state_dict(th.load(\"/n/home12/binxuwang/Github/Closed-loop-visual-insilico/checkpoints/imagenet_linf_8_pure.pt\"))\n",
    "        transforms_pipeline = T.Compose([\n",
    "            T.ToTensor(),\n",
    "            T.Resize((224, 224)),\n",
    "            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "    elif modelname == \"resnet50\":\n",
    "        model = resnet50(pretrained=True)\n",
    "        transforms_pipeline = T.Compose([\n",
    "            T.ToTensor(),\n",
    "            T.Resize((224, 224)),\n",
    "            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "    elif modelname == \"resnet50_clip\":\n",
    "        import clip\n",
    "        model_clip, preprocess = clip.load('RN50', device=device)\n",
    "        model = model_clip.visual\n",
    "        transforms_pipeline = preprocess\n",
    "    elif modelname == \"resnet50_dino\":\n",
    "        # https://github.com/facebookresearch/dino\n",
    "        model = torch.hub.load('facebookresearch/dino:main', 'dino_resnet50')\n",
    "        transforms_pipeline = T.Compose([\n",
    "            T.ToTensor(),\n",
    "            T.Resize((224, 224)),\n",
    "            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model: {modelname}\")\n",
    "        # model = timm.create_model(modelname, pretrained=True).to(device).eval()\n",
    "        # data_config = timm.data.resolve_model_data_config(model)\n",
    "        # transforms_pipeline = timm.data.create_transform(**data_config, is_training=False)\n",
    "    model = model.to(device).eval()\n",
    "    model.requires_grad_(False)\n",
    "    \n",
    "    return model, transforms_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The (227, 227) setting is overwritten by the size in custom transform\n"
     ]
    }
   ],
   "source": [
    "dataroot = r\"/n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/Projects/VVS_Accentuation\"\n",
    "data_path = join(dataroot, \"nsd_shared1000_6monkeys_2024.h5\")\n",
    "stimroot = join(dataroot, \"shared1000\")\n",
    "subject_id = 'paul_240713-240710' # 'paul_20240713-20240710' \n",
    "# modelname = \"resnet50_clip\" # \"flexivit_base.1000ep_in21k\",\n",
    "# layer_name = \"layer4\"\n",
    "# RD_method = \"pca1000\" \n",
    "batch_size = 96 \n",
    "device = \"cuda\" \n",
    "reliability_thresh = 0.7\n",
    "data_dict = load_neural_data(data_path, subject_id, stimroot)\n",
    "image_fps = data_dict['image_fps']\n",
    "resp_mat = data_dict['resp_mat']\n",
    "reliability = data_dict['reliability']\n",
    "ncsnr = data_dict['ncsnr']\n",
    "figdir = join(dataroot, \"model_outputs\", subject_id, )\n",
    "os.makedirs(figdir, exist_ok=True)\n",
    "\n",
    "for modelname in [\"resnet50_dino\", \"resnet50_robust\", \"resnet50\", \"resnet50_clip\", ]:\n",
    "    model, transforms_pipeline = load_model_transform(modelname, device=device)\n",
    "    # Load data\n",
    "    # Prepare dataset\n",
    "    dataset = ImagePathDataset(image_fps, scores=resp_mat, transform=transforms_pipeline)\n",
    "\n",
    "    batch_size = 96\n",
    "    fetcher = featureFetcher(model, input_size=(3, 224, 224), print_module=False)\n",
    "    module_names = [name for name in fetcher.module_names.values() if \"Bottleneck\" in name and (\"layer4\" in name or \"layer3\" in name)]\n",
    "    print(module_names)\n",
    "    for name in module_names: \n",
    "        fetcher.record(name, store_device='cpu', ingraph=False, )\n",
    "\n",
    "    feat_dict_lyrswp = record_features(model, fetcher, dataset, batch_size=batch_size, device=device)\n",
    "    fetcher.cleanup()\n",
    "\n",
    "    thresh = reliability_thresh\n",
    "    chan_mask = reliability > thresh\n",
    "    resp_mat_sel = resp_mat[:, chan_mask]\n",
    "    print(f\"Fitting models for reliable channels > {thresh} N={chan_mask.sum()}\")\n",
    "    result_df_lyrswp_RidgeCV, fit_models_lyrswp_RidgeCV, Xdict_lyrswp_RidgeCV, Xtfmer_lyrswp_RidgeCV = perform_regression_sweeplayer_RidgeCV(feat_dict_lyrswp, resp_mat_sel, \n",
    "                                                                            layer_names=module_names[-9:], dimred_list=[\"srp\", \"pca1000\"], \n",
    "                                                                        alpha_list=[1E-4, 1E-3, 1E-2, 1E-1, 1, 10, 100, 1E3, 1E4, 1E5, 1E6, 1E7, 1E8, 1E9],\n",
    "                                                                        verbose=True)\n",
    "    result_df_lyrswp_RidgeCV.to_csv(join(figdir, f\"{subject_id}_{modelname}_sweep_regressors_highreliab_layers_sweep_RidgeCV.csv\"))\n",
    "    th.save(fit_models_lyrswp_RidgeCV, join(figdir, f\"{subject_id}_{modelname}_sweep_regressors_highreliab_layers_fitmodels_RidgeCV.pth\")) \n",
    "    th.save(Xtfmer_lyrswp_RidgeCV, join(figdir, f\"{subject_id}_{modelname}_sweep_regressors_highreliab_layers_Xtfmer_RidgeCV.pkl\"))\n",
    "    # for half the layers (later half) ~ 20 mins\n",
    "    result_df_lyrswp_formatted = result_df_lyrswp_RidgeCV.reset_index()\n",
    "    result_df_lyrswp_formatted.rename(columns={\"level_0\": \"layer_dimred\", \"level_1\": \"regressor\", }, inplace=True)\n",
    "    result_df_lyrswp_formatted[\"layer\"] = result_df_lyrswp_formatted[\"layer_dimred\"].apply(lambda x: x.split(\"_\")[0])\n",
    "    result_df_lyrswp_formatted[\"dimred\"] = result_df_lyrswp_formatted[\"layer_dimred\"].apply(lambda x: x.split(\"_\")[-1])\n",
    "    result_df_lyrswp_formatted.to_csv(join(figdir, f\"{subject_id}_{modelname}_sweep_regressors_highreliab_layers_sweep_RidgeCV_formatted.csv\"))\n",
    "\n",
    "\n",
    "    figh, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    plt.sca(axs[0])\n",
    "    sns.lineplot(data=result_df_lyrswp_formatted, x=\"layer\", \n",
    "            y=\"train_score\", style=\"regressor\", hue=\"dimred\", ax=axs[0], marker=\"o\")\n",
    "    plt.xticks(rotation=45)\n",
    "    xticklabels = plt.gca().get_xticklabels()\n",
    "    xticklabels = [label.get_text().replace(\"Bottleneck\", \"B\").replace(\".layer\", \"L\") for label in xticklabels]\n",
    "    plt.xticks(ticks=range(len(xticklabels)), labels=xticklabels, rotation=45)\n",
    "    plt.title(\"Training R2\")\n",
    "\n",
    "    plt.sca(axs[1])\n",
    "    sns.lineplot(data=result_df_lyrswp_formatted, x=\"layer\", \n",
    "            y=\"test_score\", style=\"regressor\", hue=\"dimred\", ax=axs[1], marker=\"o\")\n",
    "    plt.xticks(rotation=45)\n",
    "    xticklabels = plt.gca().get_xticklabels()\n",
    "    xticklabels = [label.get_text().replace(\"Bottleneck\", \"B\").replace(\".layer\", \"L\") for label in xticklabels]\n",
    "    plt.xticks(ticks=range(len(xticklabels)), labels=xticklabels, rotation=45)\n",
    "    plt.title(\"Test R2\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(f\"{subject_id} {modelname} layer sweep\")\n",
    "    saveallforms(figdir, f\"{subject_id}_{modelname}_layer_sweep_GridCV_synopisis\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['brain_area',\n",
       " 'ncsnr',\n",
       " 'reliability',\n",
       " 'stim_pos',\n",
       " 'stim_size',\n",
       " 'resp_mat',\n",
       " 'resp_temp_mat',\n",
       " 'image_fps']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
