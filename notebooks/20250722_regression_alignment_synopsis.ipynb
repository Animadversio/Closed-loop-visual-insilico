{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb7602ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b2aea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from os.path import join\n",
    "import yaml\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"/n/home12/binxuwang/Github/Closed-loop-visual-insilico\")\n",
    "import yaml\n",
    "import glob\n",
    "import timm\n",
    "import torch\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "from tqdm.auto import tqdm\n",
    "from os.path import join\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from horama import maco, plot_maco\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet50\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms import ToPILImage, ToTensor, Normalize, Resize\n",
    "from circuit_toolkit.CNN_scorers import TorchScorer\n",
    "from circuit_toolkit.GAN_utils import upconvGAN, Caffenet\n",
    "from circuit_toolkit.plot_utils import to_imgrid, show_imgrid, save_imgrid, saveallforms\n",
    "from circuit_toolkit.layer_hook_utils import featureFetcher_module, featureFetcher, get_module_names\n",
    "from circuit_toolkit.dataset_utils import ImagePathDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c9c3721",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_stim_root = r\"/n/holylabs/LABS/alvarez_lab/Everyone/Accentuate_VVS/accentuation_outputs\"\n",
    "config_root = r\"/n/holylabs/LABS/alvarez_lab/Everyone/Accentuate_VVS/accentuation_configs\"\n",
    "for subject_id, filename in [\n",
    "    (\"red_20250428-20250430\", \"red_20250428-20250430_vvs-encodingstimuli_z1_rw100-400.h5\"), \n",
    "    (\"paul_20250428-20250430\", \"paul_20250428-20250430_vvs-encodingstimuli_z1_rw100-400.h5\"), \n",
    "    # (\"venus_250426-250429\", \"venus_250426-250429_vvs-encodingstimuli_z1_rw80-250.h5\"),\n",
    "    # (\"three0_250426-250501\", \"three0_250426-250501_vvs-encodingstimuli_z1_rw80-250.h5\"),\n",
    "    # (\"leap_250426-250501\", \"leap_250426-250501_vvs-encodingstimuli_z1_rw80-250.h5\"),\n",
    "]:\n",
    "    posthoc_PCA_dir = f\"/n/holylabs/LABS/alvarez_lab/Lab/VVS_Accentuation/Encoding_models/{subject_id}/posthoc_model_predict_PCA_popul_unit\"\n",
    "    os.makedirs(posthoc_PCA_dir, exist_ok=True)\n",
    "    # config_files\n",
    "    # target_subfolder = glob.glob(join(acc_stim_root, f\"*{subject_id}*_accentuation\"))\n",
    "    os.listdir(posthoc_PCA_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6108cde0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['df_accentuated_paul_20250428-20250430.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(posthoc_PCA_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a6d123a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e74be00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>unit_id</th>\n",
       "      <th>img_id</th>\n",
       "      <th>level</th>\n",
       "      <th>score</th>\n",
       "      <th>filepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AlexNet_training_seed_01</td>\n",
       "      <td>282</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.521408</td>\n",
       "      <td>-0.511481</td>\n",
       "      <td>/n/holylabs/LABS/alvarez_lab/Everyone/Accentua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AlexNet_training_seed_01</td>\n",
       "      <td>282</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.072901</td>\n",
       "      <td>-1.063394</td>\n",
       "      <td>/n/holylabs/LABS/alvarez_lab/Everyone/Accentua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AlexNet_training_seed_01</td>\n",
       "      <td>282</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.624393</td>\n",
       "      <td>-1.614484</td>\n",
       "      <td>/n/holylabs/LABS/alvarez_lab/Everyone/Accentua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AlexNet_training_seed_01</td>\n",
       "      <td>282</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.175886</td>\n",
       "      <td>-2.165995</td>\n",
       "      <td>/n/holylabs/LABS/alvarez_lab/Everyone/Accentua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AlexNet_training_seed_01</td>\n",
       "      <td>282</td>\n",
       "      <td>0</td>\n",
       "      <td>0.030085</td>\n",
       "      <td>0.039650</td>\n",
       "      <td>/n/holylabs/LABS/alvarez_lab/Everyone/Accentua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5772</th>\n",
       "      <td>siglip2_vitb16</td>\n",
       "      <td>81</td>\n",
       "      <td>9</td>\n",
       "      <td>1.992109</td>\n",
       "      <td>1.735329</td>\n",
       "      <td>/n/holylabs/LABS/alvarez_lab/Everyone/Accentua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5773</th>\n",
       "      <td>siglip2_vitb16</td>\n",
       "      <td>81</td>\n",
       "      <td>9</td>\n",
       "      <td>2.489602</td>\n",
       "      <td>1.705616</td>\n",
       "      <td>/n/holylabs/LABS/alvarez_lab/Everyone/Accentua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5774</th>\n",
       "      <td>siglip2_vitb16</td>\n",
       "      <td>81</td>\n",
       "      <td>9</td>\n",
       "      <td>2.489602</td>\n",
       "      <td>1.744846</td>\n",
       "      <td>/n/holylabs/LABS/alvarez_lab/Everyone/Accentua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5775</th>\n",
       "      <td>siglip2_vitb16</td>\n",
       "      <td>81</td>\n",
       "      <td>9</td>\n",
       "      <td>2.987096</td>\n",
       "      <td>1.699476</td>\n",
       "      <td>/n/holylabs/LABS/alvarez_lab/Everyone/Accentua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5776</th>\n",
       "      <td>siglip2_vitb16</td>\n",
       "      <td>81</td>\n",
       "      <td>9</td>\n",
       "      <td>2.987096</td>\n",
       "      <td>1.711055</td>\n",
       "      <td>/n/holylabs/LABS/alvarez_lab/Everyone/Accentua...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5777 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model_name  unit_id  img_id     level     score  \\\n",
       "0     AlexNet_training_seed_01      282       0 -0.521408 -0.511481   \n",
       "1     AlexNet_training_seed_01      282       0 -1.072901 -1.063394   \n",
       "2     AlexNet_training_seed_01      282       0 -1.624393 -1.614484   \n",
       "3     AlexNet_training_seed_01      282       0 -2.175886 -2.165995   \n",
       "4     AlexNet_training_seed_01      282       0  0.030085  0.039650   \n",
       "...                        ...      ...     ...       ...       ...   \n",
       "5772            siglip2_vitb16       81       9  1.992109  1.735329   \n",
       "5773            siglip2_vitb16       81       9  2.489602  1.705616   \n",
       "5774            siglip2_vitb16       81       9  2.489602  1.744846   \n",
       "5775            siglip2_vitb16       81       9  2.987096  1.699476   \n",
       "5776            siglip2_vitb16       81       9  2.987096  1.711055   \n",
       "\n",
       "                                               filepath  \n",
       "0     /n/holylabs/LABS/alvarez_lab/Everyone/Accentua...  \n",
       "1     /n/holylabs/LABS/alvarez_lab/Everyone/Accentua...  \n",
       "2     /n/holylabs/LABS/alvarez_lab/Everyone/Accentua...  \n",
       "3     /n/holylabs/LABS/alvarez_lab/Everyone/Accentua...  \n",
       "4     /n/holylabs/LABS/alvarez_lab/Everyone/Accentua...  \n",
       "...                                                 ...  \n",
       "5772  /n/holylabs/LABS/alvarez_lab/Everyone/Accentua...  \n",
       "5773  /n/holylabs/LABS/alvarez_lab/Everyone/Accentua...  \n",
       "5774  /n/holylabs/LABS/alvarez_lab/Everyone/Accentua...  \n",
       "5775  /n/holylabs/LABS/alvarez_lab/Everyone/Accentua...  \n",
       "5776  /n/holylabs/LABS/alvarez_lab/Everyone/Accentua...  \n",
       "\n",
       "[5777 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_acc = pd.read_pickle(\"/n/holylabs/LABS/alvarez_lab/Lab/VVS_Accentuation/Encoding_models/leap_250426-250501/posthoc_model_predict_PCA_popul_unit/df_accentuated_leap_250426-250501.pkl\")\n",
    "# pkl.load(open(\"/n/holylabs/LABS/alvarez_lab/Lab/VVS_Accentuation/Encoding_models/leap_250426-250501/posthoc_model_predict_PCA_popul_unit/df_accentuated_leap_250426-250501.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53f7b32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pkl.load(open(\"/n/holylabs/LABS/alvarez_lab/Lab/VVS_Accentuation/Encoding_models/red_20250428-20250430/posthoc_model_predict_PCA_popul_unit/posthoc_prediction_PCA_pop_unit_red_20250428-20250430_unit19_clipag_vitb32.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17fe9340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['config',\n",
       " 'df',\n",
       " 'PCA_resp',\n",
       " 'population_resp',\n",
       " 'target_unit_resp',\n",
       " 'readout_vec',\n",
       " 'readout_bias',\n",
       " 'cosine_sims',\n",
       " 'PCA_norm']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c1f0322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5500, 750])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"PCA_resp\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24816ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([750])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"readout_vec\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168be7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_root = r\"/n/holylabs/LABS/alvarez_lab/Everyone/Accentuate_VVS/accentuation_configs\"\n",
    "subject_id = \"red_20250428-20250430\"\n",
    "config_dir = join(config_root, subject_id)\n",
    "config_files = sorted(glob.glob(join(config_dir, \"*.yaml\")))\n",
    "chan_pattern = \"_Ch19_\"\n",
    "config_pre_chan = [f for f in config_files if chan_pattern in f]\n",
    "cosine_results = []\n",
    "for config_file in config_pre_chan:\n",
    "    config_acc = yaml.load(open(config_file, \"r\"), Loader=yaml.FullLoader)\n",
    "    model_name = config_acc[\"model_name\"]\n",
    "    unit_id = config_acc[\"unit_ids\"][0]\n",
    "    layer_name = config_acc[\"layer_name\"]\n",
    "    print(f\"Model: {model_name}, Unit: {unit_id}, Layer: {layer_name}\")\n",
    "    acc_split_df = df_accentuated.query(\"model_name == @model_name and unit_id == @unit_id\")\n",
    "    assert len (acc_split_df) == 110 \n",
    "\n",
    "    predict_PCA_feature, \\\n",
    "        model, transforms_pipeline, fetcher, Xtransform, readout \\\n",
    "            = get_PCA_basis_predictor_from_config(config_file, device=\"cuda\")\n",
    "    # accentuated_dataset = ImagePathDataset(acc_split_df[\"filepath\"], transform=transforms_pipeline)\n",
    "    # accentuated_dataloader = DataLoader(accentuated_dataset, batch_size=60, shuffle=False, num_workers=10)\n",
    "    acc_img_PCA_resp = get_prediction_responses(predict_PCA_feature, transforms_pipeline, \n",
    "                                        acc_split_df[\"filepath\"].tolist(), batch_size=120, num_workers=16)\n",
    "\n",
    "    acc_model_unit_PCA_resp = acc_img_PCA_resp.cpu().numpy()\n",
    "    readout_vec = readout.weight.data[unit_id, :].cpu()\n",
    "    cosine_sims = cosine_similarity(acc_model_unit_PCA_resp, readout_vec.numpy().reshape(1, -1))\n",
    "    cosine_sims = cosine_sims.flatten()\n",
    "    PCA_norm = np.linalg.norm(acc_model_unit_PCA_resp, axis=1)  \n",
    "    acc_split_df_cos = acc_split_df.copy()\n",
    "    acc_split_df_cos[\"cosine_similarity\"] = cosine_sims\n",
    "    acc_split_df_cos[\"PCA_norm\"] = PCA_norm\n",
    "    # print(f\"Cosine similarities shape: {cosine_sims.shape}\")\n",
    "    # print(f\"Mean cosine similarity: {cosine_sims.mean():.4f}\")\n",
    "    # print(f\"Std cosine similarity: {cosine_sims.std():.4f}\")\n",
    "    print(f\"Min cosine similarity: {cosine_sims.min():.4f}\")\n",
    "    print(f\"Max cosine similarity: {cosine_sims.max():.4f}\")\n",
    "    print(f\"PCA norm max {PCA_norm.max():.4f}\")\n",
    "    print(f\"PCA norm min {PCA_norm.min():.4f}\")\n",
    "    cosine_results.append({\"config\": config_acc, \n",
    "                           \"df\": acc_split_df_cos.copy(), \n",
    "                           \"PCA_resp\": acc_model_unit_PCA_resp.copy(), \n",
    "                           \"readout_vec\": readout_vec.clone(), \n",
    "                           \"cosine_sims\": cosine_sims.copy(), \n",
    "                           \"PCA_norm\": PCA_norm.copy()})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
