{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: skimage.transform is not available. Will use scipy.misc.imresize instead.\n",
      "Warning: skimage.transform is not available. Will use scipy.misc.imresize instead.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"/n/home12/binxuwang/Github/Closed-loop-visual-insilico\")\n",
    "import timm\n",
    "import torch\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "from tqdm.auto import tqdm\n",
    "from os.path import join\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from horama import maco, plot_maco\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms import ToPILImage, ToTensor, Normalize, Resize\n",
    "from torchvision.models import resnet50\n",
    "from circuit_toolkit.CNN_scorers import TorchScorer\n",
    "from circuit_toolkit.GAN_utils import upconvGAN, Caffenet\n",
    "from circuit_toolkit.plot_utils import to_imgrid, show_imgrid, save_imgrid, saveallforms\n",
    "from circuit_toolkit.layer_hook_utils import featureFetcher_module, featureFetcher, get_module_names\n",
    "from circuit_toolkit.dataset_utils import ImagePathDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from neural_regress.regress_lib import sweep_regressors\n",
    "from neural_regress.sklearn_torchify_lib import SRP_torch, PCA_torch, LinearRegression_torch, SpatialAvg_torch\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.random_projection import SparseRandomProjection, GaussianRandomProjection\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "#%% Utility Functions\n",
    "\n",
    "def load_neural_data(data_path, subject_id, stimroot):\n",
    "    \"\"\"Load neural data and image file paths.\"\"\"\n",
    "    from core.data_utils import load_from_hdf5\n",
    "    data = load_from_hdf5(data_path)\n",
    "    # Meta data\n",
    "    brain_area = data[subject_id][\"neuron_metadata\"][\"brain_area\"]\n",
    "    ncsnr = data[subject_id][\"neuron_metadata\"][\"ncsnr\"]\n",
    "    reliability = data[subject_id][\"neuron_metadata\"][\"reliability\"]\n",
    "    # Display parameters\n",
    "    stim_pos = data[subject_id]['trials']['stimulus_pos_deg']\n",
    "    stim_size = data[subject_id]['trials']['stimulus_size_pix']\n",
    "    # Response data\n",
    "    resp_mat = data[subject_id]['repavg']['response_peak']  # Peak, avg response\n",
    "    resp_temp_mat = data[subject_id]['repavg']['response_temporal']  # Temporal response\n",
    "    stimulus_names = data[subject_id]['repavg']['stimulus_name']\n",
    "    image_fps = [f\"{stimroot}/{stimname.decode('utf8')}\" for stimname in stimulus_names]\n",
    "    return {\n",
    "        'brain_area': brain_area,\n",
    "        'ncsnr': ncsnr,\n",
    "        'reliability': reliability,\n",
    "        'stim_pos': stim_pos,\n",
    "        'stim_size': stim_size,\n",
    "        'resp_mat': resp_mat,\n",
    "        'resp_temp_mat': resp_temp_mat,\n",
    "        'image_fps': image_fps,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.data_utils import load_from_hdf5\n",
    "dataroot = r\"/n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/Projects/VVS_Accentuation\"\n",
    "data_path = join(dataroot, \"nsd_shared1000_6monkeys_2024.h5\")\n",
    "data = load_from_hdf5(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['baby1_20240329-20240325',\n",
       " 'baby1_240329-240325',\n",
       " 'baby5_240819-240822',\n",
       " 'paul_20240713-20240710',\n",
       " 'paul_240713-240710',\n",
       " 'red_20240713-20240710']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trials shape: (29769,) (29769, 383)\n",
      "Rspavg shape: (1110,) (1110, 383)\n",
      "Response tensor shape (stimulus x neuron x trial): (1110, 383, 29)\n",
      "Response tensor shape: (1110, 383, 29)\n",
      "Trial counters shape: (1110,)\n",
      "min and max trial counters: 26 29\n"
     ]
    }
   ],
   "source": [
    "from core.data_utils import load_neural_trial_resp_tensor\n",
    "dataroot = r\"/n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/Projects/VVS_Accentuation\"\n",
    "data_path = join(dataroot, \"nsd_shared1000_6monkeys_2024.h5\")\n",
    "subject_id = 'paul_240713-240710'\n",
    "rspavg_stim_names, rspavg_resp_peak, resp_tensor, trial_counters = load_neural_trial_resp_tensor(data_path, subject_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['paul_20241124-20241125', 'paul_241123-241124']\n",
      "Trials shape: (3106,) (3106, 383)\n",
      "Rspavg shape: (1300,) (1300, 383)\n",
      "Response tensor shape (stimulus x neuron x trial): (1300, 383, 4)\n",
      "Response tensor shape: (1300, 383, 4)\n",
      "Trial counters shape: (1300,)\n",
      "min and max trial counters: 1 4\n"
     ]
    }
   ],
   "source": [
    "data_path = join(dataroot, \"vvs-accentuate-day3_normalize_paul_241124-25.h5\")\n",
    "data = load_from_hdf5(data_path)\n",
    "print(list(data.keys()))\n",
    "subject_id =  'paul_241123-241124'\n",
    "rspavg_stim_names, rspavg_resp_peak, resp_tensor, trial_counters = load_neural_trial_resp_tensor(data_path, subject_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trials shape: (7174,) (7174, 64)\n",
      "Rspavg shape: (1028,) (1028, 64)\n",
      "Response tensor shape (stimulus x neuron x trial): (1028, 64, 8)\n",
      "Response tensor shape: (1028, 64, 8)\n",
      "Trial counters shape: (1028,)\n",
      "min and max trial counters: 5 8\n"
     ]
    }
   ],
   "source": [
    "data_path = join(dataroot, \"vvs-accentuate-day1_normalize_paul_241119-241122.h5\")\n",
    "data = load_from_hdf5(data_path)\n",
    "list(data.keys())\n",
    "subject_id =  'paul_20241119-20241122'\n",
    "rspavg_stim_names, rspavg_resp_peak, resp_tensor, trial_counters = load_neural_trial_resp_tensor(data_path, subject_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir /n/holylabs/LABS/alvarez_lab/Lab/VVS_Accentuation/Reduced_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_dir = \"/n/holylabs/LABS/alvarez_lab/Lab/VVS_Accentuation/Reduced_Data\"\n",
    "np.savez(join(store_dir, f\"{subject_id}_trial_resp_tensor.npz\"), \n",
    "         **{'resp_tensor': resp_tensor,\n",
    "            'trial_counters': trial_counters,\n",
    "            'rspavg_stim_names': rspavg_stim_names,\n",
    "            'rspavg_resp_peak': rspavg_resp_peak,\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'clip_neg_0_2048_tr.png', b'clip_neg_0_512_tr.png',\n",
       "       b'clip_neg_1_2048_tr.png', ..., b'shared0990_nsd71929.png',\n",
       "       b'shared0994_nsd72210.png', b'shared0995_nsd72258.png'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rspavg_stim_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trials shape: (1871,) (1871, 383)\n",
      "Rspavg shape: (1028,) (1028, 383)\n",
      "Response tensor shape (stimulus x neuron x trial): (1028, 383, 2)\n",
      "Response tensor shape: (1028, 383, 2)\n",
      "Trial counters shape: (1028,)\n",
      "min and max trial counters: 1 2\n"
     ]
    }
   ],
   "source": [
    "data_path = join(dataroot, \"vvs-accentuate-day1_normalize_paul_241119.h5\")\n",
    "data = load_from_hdf5(data_path)\n",
    "list(data.keys())\n",
    "subject_id = 'paul_241119'\n",
    "rspavg_stim_names, rspavg_resp_peak, resp_tensor, trial_counters = load_neural_trial_resp_tensor(data_path, subject_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trials shape: (2330,) (2330, 383)\n",
      "Rspavg shape: (1052,) (1052, 383)\n",
      "Response tensor shape (stimulus x neuron x trial): (1052, 383, 3)\n",
      "Response tensor shape: (1052, 383, 3)\n",
      "Trial counters shape: (1052,)\n",
      "min and max trial counters: 2 3\n"
     ]
    }
   ],
   "source": [
    "data_path = join(dataroot, \"vvs-accentuate-day2_normalize_paul_241120.h5\")\n",
    "data = load_from_hdf5(data_path)\n",
    "list(data.keys())\n",
    "subject_id = 'paul_241120'\n",
    "rspavg_stim_names, rspavg_resp_peak, resp_tensor, trial_counters = load_neural_trial_resp_tensor(data_path, subject_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trials shape: (1871,) (1871, 383)\n",
      "Rspavg shape: (1028,) (1028, 383)\n",
      "Response tensor shape (stimulus x neuron x trial): (1028, 383, 2)\n",
      "Response tensor shape: (1028, 383, 2)\n",
      "Trial counters shape: (1028,)\n",
      "min and max trial counters: 1 2\n"
     ]
    }
   ],
   "source": [
    "data_path = join(dataroot, \"vvs-accentuate-day1_normalize_paul_241119.h5\")\n",
    "data = load_from_hdf5(data_path)\n",
    "list(data.keys())\n",
    "subject_id = 'paul_241119'\n",
    "rspavg_stim_names, rspavg_resp_peak, resp_tensor, trial_counters = load_neural_trial_resp_tensor(data_path, subject_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trials shape: (2330,) (2330, 383)\n",
      "Rspavg shape: (1052,) (1052, 383)\n",
      "Response tensor shape (stimulus x neuron x trial): (1052, 383, 3)\n",
      "Response tensor shape: (1052, 383, 3)\n",
      "Trial counters shape: (1052,)\n",
      "min and max trial counters: 2 3\n"
     ]
    }
   ],
   "source": [
    "data_path = join(dataroot, \"vvs-accentuate-day2_normalize_paul_241120.h5\")\n",
    "data = load_from_hdf5(data_path)\n",
    "list(data.keys())\n",
    "subject_id = 'paul_241120'\n",
    "rspavg_stim_names, rspavg_resp_peak, resp_tensor, trial_counters = load_neural_trial_resp_tensor(data_path, subject_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['paul_20241119-20241122', 'paul_241119-241122']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = join(dataroot, \"vvs-accentuate-day1_normalize_paul_241119-241122.h5\")\n",
    "data = load_from_hdf5(data_path)\n",
    "list(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29769, 383) (29769,)\n",
      "(1110, 383) (1110,)\n"
     ]
    }
   ],
   "source": [
    "subject_id = 'paul_240713-240710'\n",
    "trials_resp_peak = data[subject_id]['trials']['response_peak']\n",
    "trials_stim_names = data[subject_id]['trials']['stimulus_name']\n",
    "rspavg_resp_peak = data[subject_id]['repavg']['response_peak']\n",
    "rspavg_stim_names = data[subject_id]['repavg']['stimulus_name']\n",
    "print(trials_resp_peak.shape, trials_stim_names.shape) # (29769, 383) (29769,)\n",
    "print(rspavg_resp_peak.shape, rspavg_stim_names.shape) # (383, 1000) (383,)\n",
    "# create a tensor, stimulus by neuron by trial\n",
    "# using trials_stim_names find the index of the stimulus in rspavg_stim_names\n",
    "# then use that index to index into rspavg_resp_peak\n",
    "# then stack trials_resp_peak and the rspavg_resp_peak along the trial dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_response_tensor(trials_stim_names, trials_resp_peak, rspavg_stim_names):\n",
    "    \"\"\"Create a 3D tensor (stimulus x neuron x trial) from trial responses.\n",
    "    \n",
    "    Args:\n",
    "        trials_stim_names: Array of stimulus names for each trial\n",
    "        trials_resp_peak: Array of peak responses for each trial (trial x neuron)\n",
    "        rspavg_stim_names: Array of unique stimulus names\n",
    "        \n",
    "    Returns:\n",
    "        resp_tensor: 3D tensor of responses (stimulus x neuron x max_trials)\n",
    "        trial_counters: Number of trials per stimulus\n",
    "    \"\"\"\n",
    "    # Create a dictionary mapping stimulus names to indices\n",
    "    stim_to_idx = {name.decode('utf8'): i for i, name in enumerate(rspavg_stim_names)}\n",
    "    # Initialize list to store trial counts for each stimulus\n",
    "    trial_counts = np.zeros(len(rspavg_stim_names), dtype=int)\n",
    "    # Count trials per stimulus\n",
    "    for stim_name in trials_stim_names:\n",
    "        trial_counts[stim_to_idx[stim_name.decode('utf8')]] += 1\n",
    "    max_trials = trial_counts.max()\n",
    "    # Initialize 3D tensor (stimulus x neuron x trial)\n",
    "    resp_tensor = np.full((len(rspavg_stim_names), trials_resp_peak.shape[1], max_trials), np.nan)\n",
    "    trial_counters = np.zeros(len(rspavg_stim_names), dtype=int)\n",
    "    # Fill in the tensor with trial responses\n",
    "    for trial_idx, (stim_name, trial_resp) in enumerate(zip(trials_stim_names, trials_resp_peak)):\n",
    "        stim_idx = stim_to_idx[stim_name.decode('utf8')]\n",
    "        resp_tensor[stim_idx, :, trial_counters[stim_idx]] = trial_resp\n",
    "        trial_counters[stim_idx] += 1\n",
    "\n",
    "    print(f\"Response tensor shape (stimulus x neuron x trial): {resp_tensor.shape}\")\n",
    "    return resp_tensor, trial_counters\n",
    "\n",
    "\n",
    "def load_neural_trial_resp_tensor(data_path, subject_id,):\n",
    "    data = load_from_hdf5(data_path)\n",
    "    trials_stim_names = data[subject_id]['trials']['stimulus_name']\n",
    "    trials_resp_peak = data[subject_id]['trials']['response_peak']\n",
    "    rspavg_stim_names = data[subject_id]['repavg']['stimulus_name']\n",
    "    print(\"Trials shape:\", trials_stim_names.shape, trials_resp_peak.shape)\n",
    "    print(\"Rspavg shape:\", rspavg_stim_names.shape)\n",
    "    resp_tensor, trial_counters = create_response_tensor(trials_stim_names, trials_resp_peak, rspavg_stim_names)\n",
    "    print(\"Response tensor shape:\", resp_tensor.shape)\n",
    "    print(\"Trial counters shape:\", trial_counters.shape)\n",
    "    print(\"min and max trial counters:\", trial_counters.min(), trial_counters.max())\n",
    "    return resp_tensor, trial_counters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trials shape: (29769,) (29769, 383)\n",
      "Rspavg shape: (1110,)\n",
      "Response tensor shape (stimulus x neuron x trial): (1110, 383, 29)\n",
      "Response tensor shape: (1110, 383, 29)\n",
      "Trial counters shape: (1110,)\n",
      "min and max trial counters: 26 29\n"
     ]
    }
   ],
   "source": [
    "from core.data_utils import load_from_hdf5\n",
    "dataroot = r\"/n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/Projects/VVS_Accentuation\"\n",
    "subject_id = 'paul_240713-240710'\n",
    "resp_tensor, trial_counters = load_neural_trial_resp_tensor(data_path, subject_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response tensor shape (stimulus x neuron x trial): (1110, 383, 29)\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary mapping stimulus names to indices\n",
    "stim_to_idx = {name.decode('utf8'): i for i, name in enumerate(rspavg_stim_names)}\n",
    "\n",
    "# Initialize list to store trial counts for each stimulus\n",
    "trial_counts = np.zeros(len(rspavg_stim_names), dtype=int)\n",
    "# Count trials per stimulus\n",
    "for stim_name in trials_stim_names:\n",
    "    trial_counts[stim_to_idx[stim_name.decode('utf8')]] += 1\n",
    "max_trials = trial_counts.max()\n",
    "# Initialize 3D tensor (stimulus x neuron x trial)\n",
    "resp_tensor = np.full((len(rspavg_stim_names), trials_resp_peak.shape[1], max_trials), np.nan)\n",
    "trial_counters = np.zeros(len(rspavg_stim_names), dtype=int)\n",
    "# Fill in the tensor with trial responses\n",
    "for trial_idx, (stim_name, trial_resp) in enumerate(zip(trials_stim_names, trials_resp_peak)):\n",
    "    stim_idx = stim_to_idx[stim_name.decode('utf8')]\n",
    "    resp_tensor[stim_idx, :, trial_counters[stim_idx]] = trial_resp\n",
    "    trial_counters[stim_idx] += 1\n",
    "\n",
    "print(f\"Response tensor shape (stimulus x neuron x trial): {resp_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1110, 383, 29)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 29)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_counters.min(), trial_counters.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "927243\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# chekc no nan \n",
    "print(np.isnan(resp_tensor).sum())\n",
    "print(np.isnan(resp_tensor[:, :, :26]).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/Projects/VVS_Accentuation'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataroot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(join(dataroot, f\"{subject_id}_trial_resp_tensor.npy\"), resp_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.0K\t/n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/Projects/VVS_Accentuation/model_outputs\n",
      "6.4G\t/n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/Projects/VVS_Accentuation/nsd_shared1000_6monkeys_2024.h5\n",
      "65G\t/n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/Projects/VVS_Accentuation/paul_240713-240710\n",
      "95M\t/n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/Projects/VVS_Accentuation/paul_240713-240710_trial_resp_tensor.npy\n",
      "339M\t/n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/Projects/VVS_Accentuation/shared1000\n",
      "336M\t/n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/Projects/VVS_Accentuation/shared1000_images.tar.gz\n",
      "3.1G\t/n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/Projects/VVS_Accentuation/stimuli_pilot_20241119\n"
     ]
    }
   ],
   "source": [
    "!du -sh {dataroot}/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "idx_train, idx_test = train_test_split(\n",
    "        np.arange(1110), test_size=0.2, random_state=42, shuffle=True\n",
    "    )\n",
    "np.savez(join(dataroot, f\"{subject_id}_trial_resp_tensor_train_test_idx.npz\"), idx_train=idx_train, idx_test=idx_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
