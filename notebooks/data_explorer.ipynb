{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: skimage.transform is not available. Will use scipy.misc.imresize instead.\n",
      "Warning: skimage.transform is not available. Will use scipy.misc.imresize instead.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"/n/home12/binxuwang/Github/Closed-loop-visual-insilico\")\n",
    "import timm\n",
    "import torch\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "from tqdm.auto import tqdm\n",
    "from os.path import join\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from horama import maco, plot_maco\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms import ToPILImage, ToTensor, Normalize, Resize\n",
    "from torchvision.models import resnet50\n",
    "from circuit_toolkit.CNN_scorers import TorchScorer\n",
    "from circuit_toolkit.GAN_utils import upconvGAN, Caffenet\n",
    "from circuit_toolkit.plot_utils import to_imgrid, show_imgrid, save_imgrid, saveallforms\n",
    "from circuit_toolkit.layer_hook_utils import featureFetcher_module, featureFetcher, get_module_names\n",
    "from circuit_toolkit.dataset_utils import ImagePathDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from neural_regress.regress_lib import sweep_regressors\n",
    "from neural_regress.sklearn_torchify_lib import SRP_torch, PCA_torch, LinearRegression_torch, SpatialAvg_torch\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.random_projection import SparseRandomProjection, GaussianRandomProjection\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "#%% Utility Functions\n",
    "\n",
    "def load_neural_data(data_path, subject_id, stimroot):\n",
    "    \"\"\"Load neural data and image file paths.\"\"\"\n",
    "    from core.data_utils import load_from_hdf5\n",
    "    data = load_from_hdf5(data_path)\n",
    "    # Meta data\n",
    "    brain_area = data[subject_id][\"neuron_metadata\"][\"brain_area\"]\n",
    "    ncsnr = data[subject_id][\"neuron_metadata\"][\"ncsnr\"]\n",
    "    reliability = data[subject_id][\"neuron_metadata\"][\"reliability\"]\n",
    "    # Display parameters\n",
    "    stim_pos = data[subject_id]['trials']['stimulus_pos_deg']\n",
    "    stim_size = data[subject_id]['trials']['stimulus_size_pix']\n",
    "    # Response data\n",
    "    resp_mat = data[subject_id]['repavg']['response_peak']  # Peak, avg response\n",
    "    resp_temp_mat = data[subject_id]['repavg']['response_temporal']  # Temporal response\n",
    "    stimulus_names = data[subject_id]['repavg']['stimulus_name']\n",
    "    image_fps = [f\"{stimroot}/{stimname.decode('utf8')}\" for stimname in stimulus_names]\n",
    "    return {\n",
    "        'brain_area': brain_area,\n",
    "        'ncsnr': ncsnr,\n",
    "        'reliability': reliability,\n",
    "        'stim_pos': stim_pos,\n",
    "        'stim_size': stim_size,\n",
    "        'resp_mat': resp_mat,\n",
    "        'resp_temp_mat': resp_temp_mat,\n",
    "        'image_fps': image_fps,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.data_utils import load_from_hdf5\n",
    "dataroot = r\"/n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/Projects/VVS_Accentuation\"\n",
    "data_path = join(dataroot, \"nsd_shared1000_6monkeys_2024.h5\")\n",
    "data = load_from_hdf5(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29769, 383) (29769,)\n",
      "(1110, 383) (1110,)\n"
     ]
    }
   ],
   "source": [
    "subject_id = 'paul_240713-240710'\n",
    "trials_resp_peak = data[subject_id]['trials']['response_peak']\n",
    "trials_stim_names = data[subject_id]['trials']['stimulus_name']\n",
    "rspavg_resp_peak = data[subject_id]['repavg']['response_peak']\n",
    "rspavg_stim_names = data[subject_id]['repavg']['stimulus_name']\n",
    "\n",
    "print(trials_resp_peak.shape, trials_stim_names.shape) # (29769, 383) (29769,)\n",
    "print(rspavg_resp_peak.shape, rspavg_stim_names.shape) # (383, 1000) (383,)\n",
    "\n",
    "# create a tensor, stimulus by neuron by trial\n",
    "# using trials_stim_names find the index of the stimulus in rspavg_stim_names\n",
    "# then use that index to index into rspavg_resp_peak\n",
    "# then stack trials_resp_peak and the rspavg_resp_peak along the trial dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response tensor shape (stimulus x neuron x trial): (1110, 383, 29)\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary mapping stimulus names to indices\n",
    "stim_to_idx = {name.decode('utf8'): i for i, name in enumerate(rspavg_stim_names)}\n",
    "\n",
    "# Initialize list to store trial counts for each stimulus\n",
    "trial_counts = np.zeros(len(rspavg_stim_names), dtype=int)\n",
    "# Count trials per stimulus\n",
    "for stim_name in trials_stim_names:\n",
    "    trial_counts[stim_to_idx[stim_name.decode('utf8')]] += 1\n",
    "max_trials = trial_counts.max()\n",
    "# Initialize 3D tensor (stimulus x neuron x trial)\n",
    "resp_tensor = np.full((len(rspavg_stim_names), trials_resp_peak.shape[1], max_trials), np.nan)\n",
    "trial_counters = np.zeros(len(rspavg_stim_names), dtype=int)\n",
    "# Fill in the tensor with trial responses\n",
    "for trial_idx, (stim_name, trial_resp) in enumerate(zip(trials_stim_names, trials_resp_peak)):\n",
    "    stim_idx = stim_to_idx[stim_name.decode('utf8')]\n",
    "    resp_tensor[stim_idx, :, trial_counters[stim_idx]] = trial_resp\n",
    "    trial_counters[stim_idx] += 1\n",
    "\n",
    "print(f\"Response tensor shape (stimulus x neuron x trial): {resp_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1110, 383, 29)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 29)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_counters.min(), trial_counters.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "927243\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# chekc no nan \n",
    "print(np.isnan(resp_tensor).sum())\n",
    "print(np.isnan(resp_tensor[:, :, :26]).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/Projects/VVS_Accentuation'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataroot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(join(dataroot, f\"{subject_id}_trial_resp_tensor.npy\"), resp_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.0K\t/n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/Projects/VVS_Accentuation/model_outputs\n",
      "6.4G\t/n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/Projects/VVS_Accentuation/nsd_shared1000_6monkeys_2024.h5\n",
      "65G\t/n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/Projects/VVS_Accentuation/paul_240713-240710\n",
      "95M\t/n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/Projects/VVS_Accentuation/paul_240713-240710_trial_resp_tensor.npy\n",
      "339M\t/n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/Projects/VVS_Accentuation/shared1000\n",
      "336M\t/n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/Projects/VVS_Accentuation/shared1000_images.tar.gz\n",
      "3.1G\t/n/holylfs06/LABS/kempner_fellow_binxuwang/Users/binxuwang/Projects/VVS_Accentuation/stimuli_pilot_20241119\n"
     ]
    }
   ],
   "source": [
    "!du -sh {dataroot}/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "idx_train, idx_test = train_test_split(\n",
    "        np.arange(1110), test_size=0.2, random_state=42, shuffle=True\n",
    "    )\n",
    "np.savez(join(dataroot, f\"{subject_id}_trial_resp_tensor_train_test_idx.npz\"), idx_train=idx_train, idx_test=idx_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
